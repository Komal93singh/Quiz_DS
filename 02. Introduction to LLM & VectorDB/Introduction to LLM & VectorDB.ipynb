{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b8d5f94",
   "metadata": {},
   "source": [
    "# Quiz : Introduction to LLM & VectorDB\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ff9f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcaccd48",
   "metadata": {},
   "source": [
    "### Q1. What does LLM stand for in the context of AI? \n",
    "1. Large Linear Model \n",
    "2. Large Language Model \n",
    "3. Local Language Model \n",
    "4. Low-Level Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f909921",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Large Language Model** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e24f177",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea0cd428",
   "metadata": {},
   "source": [
    "### Q2. Which of  the following is a key component of transformers? \n",
    "1. Long Short-Term Memory (LSTM) \n",
    "2. Convolutional Layers \n",
    "3. Multi-Head Attention \n",
    "4. Recurrent Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21816cfe",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. Multi-Head Attention**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07b94d0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9355ba0",
   "metadata": {},
   "source": [
    "### Q3. What is the primary function of a vector database in AI/ML? \n",
    "1. Storing images \n",
    "2. Storing text data \n",
    "3. Storing high-dimensional vectors \n",
    "4. Storing SQL queries "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ff806e",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. Storing high-dimensional vectors**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0072a2fc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "042c0712",
   "metadata": {},
   "source": [
    "### Q4. What does BERT stand for in NLP? \n",
    "1. Bidirectional Encoder Representations from Transformers \n",
    "2. Basic Encoder Representations from Transformers \n",
    "3. Binary Encoding Representation Transformer \n",
    "4. Bidirectional Enhanced Recurrent Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8409c5",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. Bidirectional Encoder Representations from Transformers** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9e388",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe2c3ba0",
   "metadata": {},
   "source": [
    "### Q5. Which of the following is an application of Generative Adversarial Networks (GANs)? \n",
    "1. Text summarization \n",
    "2. Image generation \n",
    "3. Sentiment analysis \n",
    "4. Named entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e888f",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Image generation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13b3258",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67c0eb45",
   "metadata": {},
   "source": [
    "### Q6. What is the primary advantage of using LSTMs over traditional RNNs? \n",
    "1. Reduced computational cost \n",
    "2. Ability to handle long-term dependencies \n",
    "3. Faster training times \n",
    "4. Simpler architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c89c1ed",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Ability to handle long-term dependencies**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708279c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8818ab3",
   "metadata": {},
   "source": [
    "### Q7. Which model uses self-attention mechanisms to process sequences? 1. RNN 2. LSTM 3. Transformer 4. GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2850302b",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. Transformer** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e68ad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5194f06e",
   "metadata": {},
   "source": [
    "### Q8. What is the purpose of the 'attention' mechanism in NLP models? \n",
    "1. To reduce training time \n",
    "2. To improve model interpretability \n",
    "3. To focus on important parts of the input sequence \n",
    "4. To increase model complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87ccbe",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. To focus on important parts of the input sequence** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d6be2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "797b7305",
   "metadata": {},
   "source": [
    "### Q9. What does GRU stand for in the context of neural networks? \n",
    "1. General Recurrent Unit \n",
    "2. Gated Recurrent Unit \n",
    "3. Graph Recurrent Unit \n",
    "4. Gradient Recurrent Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5807959",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Gated Recurrent Unit**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2978bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc8148bc",
   "metadata": {},
   "source": [
    "### Q10. Which of the following is NOT a type of word embedding? \n",
    "1. One-hot encoding \n",
    "2. TF_IDF \n",
    "3. Word2Vec \n",
    "4. GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9acebab",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. TF-IDF**\n",
    "\n",
    "(TF-IDF is a statistical method, not a true word embedding like **Word2Vec** or **GloVe**.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00c385",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "405f7c3c",
   "metadata": {},
   "source": [
    "### Q11. Which vector database indexing technique is commonly used for similarity search? \n",
    "1. B-tree \n",
    "2. Approximate Nearest Neighbor (ANN) search \n",
    "3. Hashing \n",
    "4. Binary Search Tree (BST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d473104a",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Approximate Nearest Neighbor (ANN) search**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aa4799",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b62f7d9",
   "metadata": {},
   "source": [
    "### Q12. What is the primary function of the encoder in a sequence-to-sequence model? \n",
    "1. To generate output sequences \n",
    "2. To encode input sequences into a fixed-size vector \n",
    "3. To apply attention mechanisms \n",
    "4. To classify input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab19df3b",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. To encode input sequences into a fixed-size vector**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801fce2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92253bf9",
   "metadata": {},
   "source": [
    "### Q13. Which of the following models is designed to handle sequential data? \n",
    "1. Convolutional Neural Networks (CNNs) \n",
    "2. Recurrent Neural Network (RNNs) \n",
    "3. Generative Adversarial Networks (GANs) \n",
    "4. Support Vector Machines (SVMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189ce5b2",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Recurrent Neural Networks (RNNs)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd25423",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeb00c66",
   "metadata": {},
   "source": [
    "### Q14. What is the primary goal of text summarization? \n",
    "1. To classify text into categories \n",
    "2. To generate new text based on a prompt \n",
    "3. To condense text into a shorter version while retaining key information \n",
    "4. To detect named entities in text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6c4f7c",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. To condense text into a shorter version while retaining key information**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98755eb2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75352be6",
   "metadata": {},
   "source": [
    "### Q15. In the context of LSTM, what does the 'forget gate' do? \n",
    "1. It decides which information to keep from the previous cell state \n",
    "2. It updates the cell state \n",
    "3. It controls the output of the LSTM cell \n",
    "4. It generates new information from the current input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1927a6b8",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. It decides which information to keep from the previous cell state** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce88600",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "703ad605",
   "metadata": {},
   "source": [
    "### Q16. Which of the following is a characteristic of a closed-source LLM? \n",
    "1. Customizable by users \n",
    "2. Accessible through API \n",
    "3. Fully open-source code \n",
    "4. Community-driven updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801167d4",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Accessible through API**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb1b59",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc4079b3",
   "metadata": {},
   "source": [
    "### Q17. What is the role of the 'self-attention' mechanism in aTransformer model? \n",
    "1. To process data in parallel \n",
    "2. To focus on different parts of the sequence \n",
    "3. To reduce the model size \n",
    "4. To perform dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dc731b",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. To focus on different parts of the sequence**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a30a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "485cf14e",
   "metadata": {},
   "source": [
    "### Q18. How does the Transformer model improve upon RNNs? \n",
    "1. By using convolutional layers \n",
    "2. By using self-attention mechanisms \n",
    "3. By using fewer parameters \n",
    "4. By not requiring training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db95e0",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. By using self-attention mechanisms**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc0d726",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13c04714",
   "metadata": {},
   "source": [
    "### Q19. Which of the following is NOT a core component of the GPT architecture? \n",
    "1. Transformer blocks \n",
    "2. Multi-head attention \n",
    "3. Convolutional layers \n",
    "4. Feed-forward layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008eff19",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. Convolutional layers**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9464353",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50c6cdad",
   "metadata": {},
   "source": [
    "### Q20. What does the 'update gate' in a GRU do? \n",
    "1. It updates the cell state \n",
    "2. It decides which parts of the input to consider \n",
    "3. It determines the amount of information to pass from the previous state \n",
    "4. It resets the cell state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf27d7",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. It determines the amount of information to pass from the previous state**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3109d3df",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f08737b",
   "metadata": {},
   "source": [
    "### Q21. What is a primary advantage of vector databases in handling embeddings? \n",
    "1. They store raw text data \n",
    "2. They support efficient similarity searches and high-dimensional indexing \n",
    "3. They handle transactional data \n",
    "4. They only store numeric data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d56ca3a",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. They support efficient similarity searches and high-dimensional indexing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d1b8f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02a4e409",
   "metadata": {},
   "source": [
    "### Q22. Which type of attention mechanism is characterized by a weighted sum of input values? \n",
    "1. Additive attention \n",
    "2. Multiplicative attention \n",
    "3. Dot-product attention \n",
    "4. Self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb604c",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**4. Self-attention**\n",
    "\n",
    "(Self-attention computes a weighted sum of input values, where the weights are determined by the attention scores.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc526f6a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ed235d6",
   "metadata": {},
   "source": [
    "### Q23. What is the main difference between BERT and GPT models? \n",
    "1. BERT is autoregressive, while GPT is bidirectional \n",
    "2. GPT is autoregressive, while BERT is bidirectional \n",
    "3. BERT uses convolutional layers, while GPT uses attention layers \n",
    "4. GPT is used for summarization, while BERT is used for translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e39d9",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. GPT is autoregressive, while BERT is bidirectional** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa4767",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11b21876",
   "metadata": {},
   "source": [
    "### Q24. Which model is designed specifically to perform sentence classification tasks using embeddings? \n",
    "1. BERT \n",
    "2. GAN \n",
    "3. RNN \n",
    "4. Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3a51f1",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. BERT**\n",
    "\n",
    "(BERT can generate contextual embeddings that are often used for sentence-level classification tasks.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779581f3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1b89f6d",
   "metadata": {},
   "source": [
    "### Q25. In the context of NLP, what does 'tokenization' refer to? \n",
    "1. Converting text to numerical vectors \n",
    "2. Splitting text into smaller units such as words or sentences \n",
    "3. Summarizing text \n",
    "4. Generating new text based on a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b35c53",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Splitting text into smaller units such as words or sentences**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d52bea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "319826ab",
   "metadata": {},
   "source": [
    "### Q26. Which of the following is NOT a common use case of Generative Adversarial Networks (GANs)? \n",
    "1. Image synthesis \n",
    "2. Text generation \n",
    "3. Data augmentation \n",
    "4. Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ce9c1",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**4. Text classification**\n",
    "\n",
    "(GANs are primarily used for generating data, not for classifying it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26064fb3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac7fb128",
   "metadata": {},
   "source": [
    "### Q27. How does LSTM handle the vanishing gradient problem? \n",
    "1. By using gating mechanisms to control the flow of information \n",
    "2. By using convolutional layers \n",
    "3. By using attention mechanisms \n",
    "4. By using pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbbcebd",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. By using gating mechanisms to control the flow of information**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68808bfe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9862d9a",
   "metadata": {},
   "source": [
    "### Q28. What is a primary benefit of using self-attention in Transformers? \n",
    "1. It reduces the number of parameters in the model \n",
    "2. It enables the model to focus on different parts of the input sequence simultaneously \n",
    "3. It increases the training time of the model \n",
    "4. It simplifies the architecture of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c586e7",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. It enables the model to focus on different parts of the input sequence simultaneously** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df74b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35981ecf",
   "metadata": {},
   "source": [
    "### Q29. Which type of model would you use for a task requiring the generation of new text based on given input? \n",
    "1. RNN \n",
    "2. BERT \n",
    "3. GPT \n",
    "4. DBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac8fda",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. GPT** \n",
    "\n",
    "(GPT is designed for autoregressive text generation based on a given input prompt.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c725b9e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b945703",
   "metadata": {},
   "source": [
    "### Q30. What is a primary advantage of using vector databases for similarity search in AI applications? \n",
    "1. They provide high-speed transaction processing for relational data \n",
    "2. They allow for efficient querying and retrieval of high-dimensional vector data \n",
    "3. They simplify the storage of unstructured text data \n",
    "4. They offer built-in support for image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb34ac0",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. They allow for efficient querying and retrieval of high-dimensional vector data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1f195",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb4ba9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a49849",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b96d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
