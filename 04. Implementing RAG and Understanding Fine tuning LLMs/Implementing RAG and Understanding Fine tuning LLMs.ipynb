{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9ae681",
   "metadata": {},
   "source": [
    "# Quiz : Implementing RAG and Understanding Fine tuning LLMs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183a0e14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a7074d4",
   "metadata": {},
   "source": [
    "### Q1. What is the primary purpose of fine-tuning a pre-trained model? \n",
    "1. To increase the model's size \n",
    "2. To adapt the model to a specific task or domain \n",
    "3. To decrease computational requirements \n",
    "4. To improve generalization to all tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbb34c3",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. To adapt the model to a specific task or domain** \n",
    "\n",
    "Fine-tuning takes a pre-trained model (trained on large general datasets) and adjusts its weights on a smaller, task-specific dataset. This helps the model perform better on the target domain without needing to train from scratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd5683",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7689cfde",
   "metadata": {},
   "source": [
    "### Q2. In the context of LLMs, what does PEFT stand for? \n",
    "1. Parameter-Efficient Fine-Tuning \n",
    "2. Pre-trained Efficient Function Transfer \n",
    "3. Parameter Extraction for Fine-Tuning \n",
    "4. Pre-trained Efficient Feature Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d3620f",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. Parameter-Efficient Fine-Tuning (PEFT)** \n",
    "\n",
    "In the context of Large Language Models (LLMs), **PEFT** refers to techniques that fine-tune only a small subset of model parameters (like adapters, LoRA, prefix tuning) instead of updating the entire model. This makes fine-tuning more efficient in terms of computation and storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70e0c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b734743",
   "metadata": {},
   "source": [
    "### Q3. Which of the following is a regularization technique commonly used in fine-tuning? \n",
    "1. Data augmentation \n",
    "2. Dropout \n",
    "3. Gradient clipping \n",
    "4. Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e36b8aa",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Dropout** \n",
    "\n",
    "Dropout is a **regularization technique** where, during training, some neurons are randomly \"dropped\" (ignored) to prevent the model from overfitting.\n",
    "\n",
    "* **Data augmentation** → helps with generalization, but it’s more of a data-level technique.\n",
    "* **Gradient clipping** → prevents exploding gradients (stability, not regularization).\n",
    "* **Batch normalization** → stabilizes and speeds up training, not primarily for regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809fce30",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e750d4b1",
   "metadata": {},
   "source": [
    "### Q4. What is Zero-shot learning? \n",
    "1. Learning with a large dataset \n",
    "2. Learning with no labelled examples \n",
    "3. Learning with one labelled example \n",
    "4. Learning with a few labelled examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e17c90",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Learning with no labelled examples**\n",
    "\n",
    "**Zero-shot learning** means a model can perform a task **without being trained on any task-specific labeled data**. Instead, it relies on knowledge learned during pre-training and uses natural language prompts to generalize to new tasks.\n",
    "\n",
    "* **One-shot learning** → trained with just **one labeled example**.\n",
    "* **Few-shot learning** → trained with a **small number of labeled examples**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7908c6bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6acd868f",
   "metadata": {},
   "source": [
    "### Q5. Which component is crucial in Retrieval-Augmented Generation (RAG)? \n",
    "1. Decoder \n",
    "2. Retriever \n",
    "3. Encoder \n",
    "4. Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262114c4",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Retriever**\n",
    "\n",
    "In **Retrieval-Augmented Generation (RAG)**, the **retriever** is crucial because it fetches relevant information from an external knowledge base or document store. The retrieved context is then passed to the **generator (decoder)** to produce an informed, grounded response.\n",
    "\n",
    "* **Decoder** → generates the final text but depends on the retriever.\n",
    "* **Encoder** → processes inputs but isn’t the unique component of RAG.\n",
    "* **Classifier** → not used in RAG.\n",
    "\n",
    " So, the **retriever** is the key piece that makes RAG different from a standard LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384dd0e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b338d805",
   "metadata": {},
   "source": [
    "### Q6. What does RAG primarily combine in its architecture? \n",
    "1. Retrieval and generation models \n",
    "2. Classification and regression models \n",
    "3. Supervised and unsupervised learning \n",
    "4. Data augmentation and regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a2ca46",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. Retrieval and generation models**\n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)** combines:\n",
    "\n",
    "* A **retriever** → to fetch relevant external knowledge (e.g., from a vector database).\n",
    "* A **generator** (usually an LLM decoder) → to generate a context-aware response using both the query and retrieved information.\n",
    "\n",
    "This way, RAG grounds model outputs in **real-world knowledge** instead of relying only on parametric memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c351668d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "302884ae",
   "metadata": {},
   "source": [
    "### Q7. Which of the following is an advantage of fine-tuning over training from scratch?\n",
    "1. Requires more data \n",
    "2. Requires less computation \n",
    "3. Increases model size \n",
    "4. Decreases model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d6fad1",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Requires less computation**\n",
    "\n",
    "Fine-tuning starts from a **pre-trained model** (already trained on large datasets), so it:\n",
    "\n",
    "* Needs **less data** and **less compute** than training from scratch.\n",
    "* Achieves **faster convergence**.\n",
    "* Often gives **better accuracy** for domain-specific tasks.\n",
    "\n",
    "Training from scratch, on the other hand, requires **massive data and compute resources**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917cd901",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5bb9dad",
   "metadata": {},
   "source": [
    "### Q8. Few-shot learning is more useful when: \n",
    "1. Large labelled datasets are available \n",
    "2. Limited labelled data is available \n",
    "3. There is no data available \n",
    "4. The task is unrelated to the pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36577659",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Limited labelled data is available**\n",
    "\n",
    "**Few-shot learning** is especially useful when you only have a **small number of labeled examples** for a task. The model leverages its pre-trained knowledge and adapts quickly with those few samples.\n",
    "\n",
    "* If **large labeled datasets** exist → full training/fine-tuning works better.\n",
    "* If **no data** → zero-shot learning is the approach.\n",
    "* If the **task is unrelated to the pre-trained model** → even few-shot may not work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f015f5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d4c109e",
   "metadata": {},
   "source": [
    "### Q9. Which method prevents overfitting during fine-tuning? \n",
    "1. Increasing learning rate \n",
    "2. Regularization techniques \n",
    "3. Reducing the number of layers \n",
    "4. Increasing dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4af13c",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Regularization techniques**\n",
    "\n",
    "During fine-tuning, **regularization methods** like **dropout, weight decay, early stopping, or layer freezing** are commonly used to prevent overfitting.\n",
    "\n",
    "* **Increasing learning rate** → usually causes instability, not prevention.\n",
    "* **Reducing the number of layers** → may simplify the model but doesn’t directly target overfitting.\n",
    "* **Increasing dataset size** → helps, but it’s a data strategy, not a direct training method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a64ed0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad89567a",
   "metadata": {},
   "source": [
    "### Q10. What is a key advantage of RAG over traditional generation methods? \n",
    "1. Faster inference time \n",
    "2. Enhanced relevance and accuracy \n",
    "3. Smaller model size \n",
    "4. Easier to implement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb58bf",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Enhanced relevance and accuracy**\n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)** improves responses by pulling **up-to-date and domain-specific knowledge** from external sources, instead of relying only on what’s stored in the model’s parameters.\n",
    "\n",
    "* **Faster inference time** → not always true (retrieval can add latency).\n",
    "* **Smaller model size** → RAG doesn’t reduce model size; it adds retrieval.\n",
    "* **Easier to implement** → it’s actually more complex than plain generation.\n",
    "\n",
    "So the **key advantage** is that RAG produces **more relevant, factual, and accurate answers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb304579",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d7244a0",
   "metadata": {},
   "source": [
    "### Q11. In PEFT, which technique allows fine-tuning fewer parameters while maintaining performance? \n",
    "1. Low-Rank Adaptation (LoRA) \n",
    "2. Data augmentation \n",
    "3. Transfer learning \n",
    "4. Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5f0b43",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. Low-Rank Adaptation (LoRA)**\n",
    "\n",
    "In **Parameter-Efficient Fine-Tuning (PEFT)**, **LoRA** inserts small low-rank matrices into the transformer layers and trains only those, while keeping most of the pre-trained weights frozen.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "* Fine-tunes **fewer parameters**.\n",
    "* Uses **less memory and compute**.\n",
    "* Maintains performance close to full fine-tuning.\n",
    "\n",
    "The other options don’t fit:\n",
    "\n",
    "* **Data augmentation** → improves generalization, not PEFT-specific.\n",
    "* **Transfer learning** → broader concept, not a PEFT method itself.\n",
    "* **Early stopping** → prevents overfitting, not for reducing trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3902f66",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23faace5",
   "metadata": {},
   "source": [
    "### Q12. Which regularization technique penalizes the magnitude of model weights? \n",
    "1. Dropout \n",
    "2. Weight decay \n",
    "3. Batch normalization \n",
    "4. Gradient clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4694e175",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Weight decay**\n",
    "\n",
    "**Weight decay** (also called **L2 regularization**) discourages large weight values by adding a penalty proportional to the square of the weights’ magnitude to the loss function. This helps prevent overfitting and improves generalization.\n",
    "\n",
    "* **Dropout** → randomly drops neurons during training.\n",
    "* **Batch normalization** → normalizes activations for stability, not weight penalization.\n",
    "* **Gradient clipping** → limits gradient size to avoid exploding gradients, not regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cddfabf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2abd785",
   "metadata": {},
   "source": [
    "### Q13. What is the main role of the generator in a RAG system? \n",
    "1. Retrieve relevant documents \n",
    "2. Generate text based on retrieved information \n",
    "3. Classify input data \n",
    "4. Encode input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23bfaf2",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Generate text based on retrieved information**\n",
    "\n",
    "In a **Retrieval-Augmented Generation (RAG)** system:\n",
    "\n",
    "* The **retriever** → fetches relevant documents from an external knowledge base.\n",
    "* The **generator** → uses both the **input query + retrieved context** to produce a coherent, informed response.\n",
    "\n",
    "So, the **generator’s main role** is to **generate grounded text**, rather than memorized or hallucinated content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b389b46d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a76473b",
   "metadata": {},
   "source": [
    "### Q14. How does fine-tuning improve a pre-trained model's performance on a new task? \n",
    "1. By reducing the model's parameters \n",
    "2. By re-training the entire model from scratch \n",
    "3. By adjusting the model's weights based on new task-specific data \n",
    "4. By using a larger pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f828a52",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. By adjusting the model's weights based on new task-specific data**\n",
    "\n",
    "Fine-tuning takes a **pre-trained model** (trained on large general datasets) and slightly **updates its weights** using **smaller, task-specific data**. This lets the model adapt to the new domain/task while retaining its general knowledge.\n",
    "\n",
    "* **Reducing parameters** → not the main mechanism.\n",
    "* **Re-training from scratch** → opposite of fine-tuning.\n",
    "* **Using a larger model** → can help, but that’s scaling, not fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0fc9db",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e6039cc",
   "metadata": {},
   "source": [
    "### Q15. Which of the following is true about few-shot learning? \n",
    "1. It requires a completely new model architecture \n",
    "2. It uses only a few labelled examples for training \n",
    "3. It is less effective than zero-shot learning \n",
    "4. It cannot be combined with transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366a3f6",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. It uses only a few labelled examples for training** \n",
    "\n",
    "**Few-shot learning** allows a model to adapt to a task with just a handful of labeled examples, leveraging its **pre-trained knowledge**.\n",
    "\n",
    "* **1. Requires a new architecture** → No, it works with existing architectures like LLMs.\n",
    "* **3. Less effective than zero-shot** → Usually **more effective**, since it gets at least some supervision.\n",
    "* **4. Cannot be combined with transfer learning** → In fact, it’s often built on top of transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0d1d7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46e5ebf0",
   "metadata": {},
   "source": [
    "### Q16. In RAG, what is the purpose of integrating a knowledge base? \n",
    "1. To speed up model training \n",
    "2. To improve the generation of relevant and accurate responses \n",
    "3. To reduce the model's size \n",
    "4. To simplify the architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80138e1",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. To improve the generation of relevant and accurate responses**\n",
    "\n",
    "In **Retrieval-Augmented Generation (RAG)**, the **knowledge base** provides up-to-date, domain-specific, or factual information that the retriever can fetch. The generator then uses this context to create **more accurate, grounded, and relevant outputs**.\n",
    "\n",
    "* **1. Speed up training** → retrieval usually adds complexity.\n",
    "* **3. Reduce model size** → RAG doesn’t shrink models.\n",
    "* **4. Simplify architecture** → it actually makes it more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939c5c4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23c78ed7",
   "metadata": {},
   "source": [
    "### Q17. What is a common challenge in fine-tuning large language models (LLMs)? \n",
    "1. Overfitting to the new task \n",
    "2. Underfitting the pre-trained model \n",
    "3. Lack of pre-trained models \n",
    "4. Too few parameters to adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d7306a",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. Overfitting to the new task** \n",
    "\n",
    "A **common challenge in fine-tuning LLMs** is that with **small task-specific datasets**, the model may **overfit** — it memorizes the training data instead of generalizing.\n",
    "\n",
    "* **2. Underfitting** → less common, since LLMs are already powerful.\n",
    "* **3. Lack of pre-trained models** → not true today; many are available (GPT, LLaMA, etc.).\n",
    "* **4. Too few parameters to adjust** → the opposite problem; LLMs have *billions* of parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75e2e0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e72f78b1",
   "metadata": {},
   "source": [
    "### Q18. Which technique in fine-tuning involves freezing certain layers of the model? \n",
    "1. Full fine-tuning \n",
    "2. Layer-wise fine-tuning \n",
    "3. Partial fine-tuning \n",
    "4. Selective fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e3aafa",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**4. Selective fine-tuning**\n",
    "\n",
    "In **selective fine-tuning**, some layers of the pre-trained model are **frozen** (weights not updated), while only specific layers (usually the last few or task-specific heads) are fine-tuned.\n",
    "\n",
    "* **1. Full fine-tuning** → updates **all** layers.\n",
    "* **2. Layer-wise fine-tuning** → gradually unfreezes layers during training.\n",
    "* **3. Partial fine-tuning** → general term, but not the standard name for freezing.\n",
    "\n",
    "Selective fine-tuning is especially useful for **reducing compute cost** and **avoiding overfitting** on small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6d6bb6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b98158e",
   "metadata": {},
   "source": [
    "### Q19. Why is retrieval important in RAG systems? \n",
    "1. It reduces the complexity of the model \n",
    "2. It retrieves relevant documents to enhance the generation process \n",
    "3. It decreases training time \n",
    "4. It simplifies data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84039726",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. It retrieves relevant documents to enhance the generation process** \n",
    "\n",
    "In **Retrieval-Augmented Generation (RAG)**, the **retriever** fetches relevant documents or knowledge snippets from an external knowledge base. This additional context helps the generator produce **more factual, relevant, and grounded responses**.\n",
    "\n",
    "* **1. Reduces complexity** → retrieval actually adds complexity.\n",
    "* **3. Decreases training time** → not the main purpose.\n",
    "* **4. Simplifies preprocessing** → unrelated.\n",
    "\n",
    "Retrieval is what makes RAG stand out compared to plain LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac39ba2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8e2d92c",
   "metadata": {},
   "source": [
    "### Q20. Which aspect of fine-tuning requires careful adjustment to prevent overfitting? \n",
    "1. Learning rate \n",
    "2. Dataset size \n",
    "3. Model architecture \n",
    "4. Number of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc996f9",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. Learning rate**\n",
    "\n",
    "In **fine-tuning**, the **learning rate** is crucial — if it’s too high, the model may overwrite useful pre-trained knowledge; if it’s too low, training may be too slow or ineffective. A poorly tuned learning rate often leads to **overfitting or catastrophic forgetting**.\n",
    "\n",
    "* **2. Dataset size** → matters, but it’s not an adjustable hyperparameter.\n",
    "* **3. Model architecture** → fixed once chosen; not usually changed during fine-tuning.\n",
    "* **4. Number of layers** → can be frozen/unfrozen, but overfitting risk is most sensitive to learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9fea13",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32dda0f9",
   "metadata": {},
   "source": [
    "### Q21. Which PEFT technique focuses on adjusting only a subset of model weights? \n",
    "1. Fine-tuning the entire model \n",
    "2. Layer-wise tuning \n",
    "3. Low-rank adaptation (LoRA) \n",
    "4. Full model retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfffb39c",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. Low-Rank Adaptation (LoRA)**\n",
    "\n",
    "**LoRA** is a **Parameter-Efficient Fine-Tuning (PEFT)** technique that:\n",
    "\n",
    "* Keeps most of the pre-trained model’s weights **frozen**.\n",
    "\n",
    "* Inserts **small low-rank trainable matrices** into specific layers (like attention layers).\n",
    "\n",
    "* Adjusts **only a subset of weights**, reducing memory and compute costs.\n",
    "\n",
    "* **1. Fine-tuning the entire model** → opposite of PEFT.\n",
    "\n",
    "* **2. Layer-wise tuning** → progressively unfreezing layers, not subset weight adjustment.\n",
    "\n",
    "* **4. Full model retraining** → requires updating all weights from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a7ada",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a912175",
   "metadata": {},
   "source": [
    "### Q22. What is the key advantage of using zero-shot learning in LLMs? \n",
    "1. Requires extensive labelled data \n",
    "2. Achieves high accuracy with no task-specific training data \n",
    "3. Simplifies the model architecture \n",
    "4. Enhances transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedaf1d7",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Achieves high accuracy with no task-specific training data**\n",
    "\n",
    "**Zero-shot learning** lets an LLM perform a task **without seeing any labeled examples** from that task during training. Instead, it relies on **knowledge gained during pre-training** and **natural language prompts** to generalize.\n",
    "\n",
    "* **1. Requires extensive labelled data** → opposite of zero-shot.\n",
    "* **3. Simplifies architecture** → no change to architecture.\n",
    "* **4. Enhances transfer learning** → related, but not the key advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd7fb5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc59eb7a",
   "metadata": {},
   "source": [
    "### Q23. In a RAG system, how does the interaction between retriever and generator enhance performance? \n",
    "1. By generating longer text sequences \n",
    "2. By improving the relevance and context of generated content \n",
    "3. By reducing computational complexity \n",
    "4. By increasing the model's capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75ebfe7",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. By improving the relevance and context of generated content** \n",
    "\n",
    "In a **Retrieval-Augmented Generation (RAG)** system:\n",
    "\n",
    "* The **retriever** fetches relevant documents from a knowledge base.\n",
    "* The **generator** uses both the **query + retrieved context** to produce responses.\n",
    "\n",
    "This interaction ensures outputs are **more accurate, contextual, and grounded in real data**, reducing hallucinations.\n",
    "\n",
    "* **1. Generating longer text** → not the goal.\n",
    "* **3. Reducing computational complexity** → retrieval adds complexity.\n",
    "* **4. Increasing model capacity** → model size stays the same; performance improves through external knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144a2a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "130c3651",
   "metadata": {},
   "source": [
    "### Q24. Which regularization technique is particularly useful in preventing overfitting in large models during fine-tuning? \n",
    "1. Weight decay \n",
    "2. Data augmentation \n",
    "3. Dropout \n",
    "4. Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd57ab84",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. Dropout**\n",
    "\n",
    "**Dropout** is especially effective in **large models** during fine-tuning. It randomly “drops” (sets to zero) a fraction of neurons during training, forcing the model to rely on multiple pathways rather than memorizing patterns. This helps reduce **overfitting**.\n",
    "\n",
    "* **1. Weight decay** → useful, but dropout is more impactful for very large models.\n",
    "* **2. Data augmentation** → good, but more common in vision tasks.\n",
    "* **4. Batch normalization** → stabilizes training, not mainly for overfitting prevention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f15cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aad5c94f",
   "metadata": {},
   "source": [
    "### Q25. What is a key challenge when implementing RAG in real-time applications? \n",
    "1. Synchronizing the retrieval and generation processes \n",
    "2. Reducing the size of the retriever module \n",
    "3. Scaling the model to larger datasets \n",
    "4. Simplifying the architecture for faster deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5088702",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. Synchronizing the retrieval and generation processes**\n",
    "\n",
    "In **real-time RAG applications**, the main challenge is ensuring that:\n",
    "\n",
    "* The **retriever** quickly finds the most relevant documents.\n",
    "* The **generator** seamlessly integrates that information to produce a coherent, context-aware response.\n",
    "\n",
    "This synchronization is difficult because retrieval can introduce **latency**, and poor alignment can reduce response quality.\n",
    "\n",
    "* **2. Reducing retriever size** → not the main bottleneck.\n",
    "* **3. Scaling to larger datasets** → important, but more of an offline/data engineering challenge.\n",
    "* **4. Simplifying architecture** → RAG is inherently more complex; the bigger issue is real-time coordination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b7d529",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "113eda4e",
   "metadata": {},
   "source": [
    "### Q26. Why is it important to balance generalization and specialization in LLMs during fine-tuning? \n",
    "1. To maximize model size \n",
    "2. To prevent overfitting to specific tasks \n",
    "3. To reduce computational requirements \n",
    "4. To increase training speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8982f975",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. To prevent overfitting to specific tasks**\n",
    "\n",
    "During **fine-tuning of LLMs**, there’s a trade-off:\n",
    "\n",
    "* **Generalization** → retaining broad knowledge from pre-training.\n",
    "* **Specialization** → adapting to the new task/domain.\n",
    "\n",
    "If the balance is lost, the model may:\n",
    "\n",
    "* **Overfit** → perform well only on the fine-tuned task but lose general abilities.\n",
    "* **Underfit** → fail to adapt properly to the new domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b8698",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9285309",
   "metadata": {},
   "source": [
    "### Q27. How does few-shot learning differ from traditional supervised learning? \n",
    "1. It requires a large amount of labelled data \n",
    "2. It generalizes better from a smaller number of examples \n",
    "3. It is less accurate than tradition methods \n",
    "4. It requires completely new model architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e1e40a",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. It generalizes better from a smaller number of examples** \n",
    "\n",
    "**Few-shot learning** is different from traditional supervised learning because:\n",
    "\n",
    "* It works with **very limited labeled data** (a few examples per class/task).\n",
    "* It leverages **pre-trained knowledge** to generalize from those few examples.\n",
    "\n",
    "In contrast, **traditional supervised learning** usually needs **large labeled datasets** to achieve good performance.\n",
    "\n",
    "* **1. Requires large data** → opposite of few-shot.\n",
    "* **3. Less accurate** → not always true; often competitive.\n",
    "* **4. Requires new architectures** → often works with existing LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa45614a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4801a198",
   "metadata": {},
   "source": [
    "### Q28. What role does the generator play in improving RAG's performance? \n",
    "1. It selects relevant documents \n",
    "2. It encodes input data \n",
    "3. It generates responses based on retrieved documents \n",
    "4. It reduces model size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deec11a1",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. It generates responses based on retrieved documents**\n",
    "\n",
    "In **Retrieval-Augmented Generation (RAG)**:\n",
    "\n",
    "* The **retriever** → fetches relevant documents from the knowledge base.\n",
    "\n",
    "* The **generator** → combines the **input query + retrieved context** to produce accurate, grounded, and coherent responses.\n",
    "\n",
    "* **1. Selects relevant documents** → that’s the retriever’s job.\n",
    "\n",
    "* **2. Encodes input data** → handled by encoder components.\n",
    "\n",
    "* **4. Reduces model size** → RAG doesn’t shrink models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a475d76a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f050b34",
   "metadata": {},
   "source": [
    "### Q29. Which approach can be used to prevent overfitting during LLM fine-tuning? \n",
    "1. Increasing the learning rate \n",
    "2. Using smaller datasets \n",
    "3. Applying dropout and weight decay \n",
    "4. Removing regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cedd46",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. Applying dropout and weight decay**\n",
    "\n",
    "To **prevent overfitting** in LLM fine-tuning, common strategies include:\n",
    "\n",
    "* **Dropout** → randomly drops neurons during training.\n",
    "\n",
    "* **Weight decay (L2 regularization)** → penalizes large weights.\n",
    "\n",
    "* **Early stopping, layer freezing, and data augmentation** can also help.\n",
    "\n",
    "* **1. Increasing learning rate** → usually worsens overfitting.\n",
    "\n",
    "* **2. Using smaller datasets** → makes overfitting worse.\n",
    "\n",
    "* **4. Removing regularization** → increases overfitting risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4f04c1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd3a692f",
   "metadata": {},
   "source": [
    "### Q30. When would you prefer using RAG over a fine-tuned model? \n",
    "1. When the task requires generating creative content \n",
    "2. When external knowledge or specific information retrieval is crucial \n",
    "3. Whwn fine-tuning is not computationally feasible\n",
    "4. When general-purpose responses are needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a48938",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. When external knowledge or specific information retrieval is crucial** \n",
    "\n",
    "**RAG (Retrieval-Augmented Generation)** is preferred when:\n",
    "\n",
    "* The model needs **up-to-date or domain-specific knowledge**.\n",
    "\n",
    "* The information required is **too large or dynamic** to store in model parameters.\n",
    "\n",
    "* Example: customer support chatbots, legal/medical assistants, research tools.\n",
    "\n",
    "* **1. Creative content** → a fine-tuned model or base LLM works better.\n",
    "\n",
    "* **4. General-purpose responses** → fine-tuned or pre-trained models are sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834f1f4c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecb13c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defc2ebe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8bf9bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
